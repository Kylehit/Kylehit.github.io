[{"title":"Bash Command Line Basics","url":"/2020/07/03/Bash Command Line/","content":"\n# Bash Command Line\n\n## Basics\n\nls -F  show files or directories\n\nls -F -a   == ls -Fa   show all files and directories (including hidden ones) (there is . before the name)\n\ncd     --> to home directory (user)\n\ncd /   ---> to the top unix directory (root)\n\ncd -   --> back to previous directory\n\nman   ---> manual page\n\n- q  quit\n- b  previous page \n- space  next page\n- \n\nls --help\n\ncd c ---> give all the possible expansion starts with 'c'\n\n\n\n### Creating things\n\nmkdir\n\nnano --- create and edit txt file\n\ncat  ----- show file content\n\nrm -r --- recursively remove directories\n\nrmdir  --- remove directories (cannot remove when there are files in the directories)\n\n\n\nls -l --- file attributes\n\nmv  \n\n- mv chapter1/draft.txt chapter1/backup.txt ./    (move files)\n- rename files\n\ncp \n\n## Compress and extract files\n\ntar cvf data.tar data-shell/\n\n- cvf --- c creating/archive  v visualize f  put all files in data-shell/ into data.tar (using the following tar archive for the operation)\n- xvf -- x unpack\n- cvfz --- archive and using gzip to compress\n  - tar cvfz data.tar.gz data-shell/\n- xvfz -- unzip the gz and unarchive the tar\n\ngzip\n\n- more efficient compression to '.gz'\n\nunzip\n\n- Unzip the zip file\n\ncltrl + L --- clean the screen\n\nhistory --- show history commands\n\n`tar` is by far the most widely used archiving tool on UNIX-like systems. Since it was originally designed for sequential write/read on magnetic tapes, it does not index data for random access to its contents. A number of 3rd-party tools can add indexing to `tar`. However, there is a modern version of `tar` called **DAR** (stands for Disk ARchiver) that has some nice features:\n\n- each DAR archive includes an index for fast file list/restore,\n- DAR supports full / differential / incremental backup,\n- DAR has build-in compression on a file-by-file basis to make it more resilient against data corruption and to avoid compressing already compressed files such as video,\n- DAR supports strong encryption,\n- DAR can detect corruption in both headers and saved data and recover with minimal data loss,\n\nand so on. Learning DAR is not part of this course. In the future, if you want to know more about working with DAR, please watch our [DAR webinar](https://westgrid.github.io/trainingMaterials/tools/rdm) (scroll down to see it).\n\n\n\n### File Transfer\n\nsecurely transfer file between remote system and local system\n\n`scp` : need RSA key\n\n`sftp`\n\n`scp` is useful, but what if we don’t know the exact location of what we want to transfer? Or perhaps we’re simply not sure which files we want to transfer yet. `sftp` is an interactive way of downloading and uploading files. Let’s connect to a cluster with `sftp`:\n\n```fallback\n[local]$ sftp userXXX@cassiopeia.c3.ca\n```\n\nThis will start what appears to be a shell with the prompt `sftp>`. However, we only have access to a limited number of commands. We can see which commands are available with `help`:\n\n```fallback\nsftp> help\nAvailable commands:\nbye                                Quit sftp\ncd path                            Change remote directory to 'path'\nchgrp grp path                     Change group of file 'path' to 'grp'\nchmod mode path                    Change permissions of file 'path' to 'mode'\nchown own path                     Change owner of file 'path' to 'own'\ndf [-hi] [path]                    Display statistics for current directory or\n                                   filesystem containing 'path'\nexit                               Quit sftp\nget [-afPpRr] remote [local]       Download file\nreget [-fPpRr] remote [local]      Resume download file\nreput [-fPpRr] [local] remote      Resume upload file\nhelp                               Display this help text\nlcd path                           Change local directory to 'path'\nlls [ls-options [path]]            Display local directory listing\nlmkdir path                        Create local directory\nln [-s] oldpath newpath            Link remote file (-s for symlink)\nlpwd                               Print local working directory\nls [-1afhlnrSt] [path]             Display remote directory listing\n...\n```\n\nNotice the presence of multiple commands that make mention of local and remote. We are actually browsing two filesystems at once, with two working directories!\n\n```fallback\nsftp> pwd    # show our remote working directory\nsftp> lpwd   # show our local working directory\nsftp> ls     # show the contents of our remote directory\nsftp> lls    # show the contents of our local directory\nsftp> cd     # change the remote directory\nsftp> lcd    # change the local directory\nsftp> put localFile    # upload a file\nsftp> get remoteFile   # download a file\n```\n\nAnd we can recursively put/get files by just adding `-r`. Note that the directory needs to be present beforehand:\n\n```fallback\nsftp> mkdir content\nsftp> put -r content/\n```\n\nTo quit, type `exit` or `bye`.\n\n> **Exercise:** Using one of the above methods, try transferring files to and from the cluster. For example, you can download bfiles.tar.gz to your laptop. Which method do you like best?\n\n**Note on Windows**:\n\n- When you transfer files to from a Windows system to a Unix system (Mac, Linux, BSD, Solaris, etc.) this can cause problems. Windows encodes its files slightly different than Unix, and adds an extra character to every line.\n- On a Unix system, every line in a file ends with a `\\n` (newline). On Windows, every line in a file ends with a `\\r\\n` (carriage return + newline). This causes problems sometimes.\n- You can identify if a file has Windows line endings with `cat -A filename`. A file with Windows line endings will have `^M$` at the end of every line. A file with Unix line endings will have `$` at the end of a line.\n- Though most modern programming languages and software handles this correctly, in some rare instances, you may run into an issue. The solution is to convert a file from Windows to Unix encoding with the `dos2unix filename` command. Conversely, to convert back to Windows format, you can run `unix2dos filename`.\n\n**Note on syncing**: there also a command `rsync` for synching two directories. It is super useful, especially for work in progress. For example, you can use it the download all the latest PNG images from your working directory on the cluster.\n\n\n\n### Tapping the power of Unix\n\n#### Wildcards, redirection to files and pipes\n\nls p*\n\nls \\*th\\* \n\n\n\nwc --word count \n\n- wc ethan.pdb\n  - 12  84 622 ethane.pdb\n  - \\#of lines  # of words  # of characters \n  - also 622 bytes\n- wc -l *.pdb\n- wc -l *.pdb > list.txt   \n  - write the output into the file (standard output redirection to a file)\n\nsort -n list.txt > sort.txt \n\n- -n  numerically\n\nhead -3 sort.txt\n\n- print first 3 lines of the file\n\ntail -3 sort.txt\n\n- print last 3 lines of the file\n\n  \n\n**Constructing complex commands with Unix pipes**\n\nFor example,\n\nwc -l *.pdb > list.txt\n\nsort -n list.txt > sort.txt\n\nhead -1 sort.txt\n\n*construct these three lines into a single command ?*\n\n`wc -l *.pdb | sort -n | head -1`\n\n\n\n## Aliases\n\nAliases are one-line shortcuts/abbreviation to avoid typing a longer command, e.g.\n\n```fallback\n$ alias ls='ls -aFh'\n$ alias pwd='pwd -P'\n$ alias hi='history'\n$ alias top='top -o cpu -s 10 -stats \"pid,command,cpu,mem,threads,state,user\"'\n$ alias cedar='ssh -Y cedar.computecanada.ca'\n$ alias weather='curl wttr.in/vancouver'\n$ alias cal='gcal --starting-day=1'  # starts on Monday\n```\n\nNow, instead of typing `ssh -Y cedar.computecanada.ca`, you can simply type `cedar`. To see all your defined aliases, type `alias`. To remove, e.g. the alias `cedar`, type `unalias cedar`.\n\nYou may want to put all your alias definitions into the file `~/.bashrc` which is run every time you start a new local or remote shell.\n\n\n\n### Bash Loops\n\necho --- print whatever behind this command\n\nTo print the value of a variable, we need `echo $variable`\n\nA easy example of `for` loop\n\n```bash\nfor file in *.dat\ndo\necho $file\ndone\n```\n\nor we could write this easy example in one line by using semicolon.\n\n```bash\nfor file in *.dat; do echo $file; done\n```\n\nA *collection* is required behind `in`.\n\nWe could create collections in several examples:\n\n```bash\necho {1..10}\necho {1,2,5}\necho {a..c}\n```\n\nAbove two commands will create and output two collections as\n\n1 2 3 4 5 6 7 8 9 10\n\n1 2 5 \n\na b c\n\nNote the collection is not a string.\n\n#### substrings\n\n${variable:0:3}  ---- the first 3 characters of string variable\n\nExample: substract characters from strings\n\n\n\n### Exercise1\n\nwriting info into .bashrc is better.\n\n.bashrc_profile\n\n\n\n\\> v.s. >>\n\n- \\> will overwrite the contents of the file\n- \\>> will contancate the content to the end of the file\n\n`diff` -- compare files and folders\n\n`touch`\n\n​\ttouch a{1..100}.txt  ---- create 100 empty files named as a*.txt\n\n \techo {a..z}{1..2} ---- a1 a2 b1 b2 .....\n\n​\t echo  a{1..3}.{txt,py}\n\n`ps`  show all the process\n\n​\tps aux --- show all users'\n\n`kill`\n\n​\tkill PID\n\n​    kill -9 PID  ----> strongest killer\n\nuniq ---\n\n\n\n`rsync`\n\nrsync -Pva --inplace user120@cassiopeia.c3.ca:thesis/ .\n\n\n\nUsing Unix pipes, write a one-line command to show the name of the longest ***.pdb** file (by the number of lines). Paste your answer here.\n\n\n\n wc -l *pdb | sort -n | tail -2 | head -1\n\n\n\n\n\n**PS1=\"\\u@\\h \\w> \"**   --- changing the prompt\n\nthis variable is just in this shell\n\n\n\n[user144@login1 ~]$ echo tmp/data-shell/molecules/*\ntmp/data-shell/molecules/a.txt tmp/data-shell/molecules/cubane.pdb tmp/data-shell/molecules/ethane.pdb tmp/data-shell/molecules/list.txt tmp/data-shell/molecules/methane.pdb tmp/data-shell/molecules/octane.pdb tmp/data-shell/molecules/pentane.pdb tmp/data-shell/molecules/propane.pdb tmp/data-shell/molecules/sort.txt\n\n\n\n**for i in hello 1 2 \\* bye; do echo $i; done**\n\nThis command will print the hello 1 2 and all files and directories in current directory and bye\n\n\n\n```\nvar=\"sun\"\necho $varshine\necho ${var}shine\necho \"$var\"shine\n```\n\n\n\nRedirection\n\nDefault to the terminal\n\nmkdirr tmp 2> error.txt\n\nThe error will go into the file\n\nmkdirr tmp 1>error.txt\n\nonly to terminal\n\nmkdirr tmp &> error.txt\n\nboth to file and terminal\n\n\n\n/dev/null is a 'blackhole'\n\n\n\nmkdir tmp ; cd tmp\n\nrun second command no matter the results of first command\n\nmkdirr tmp && cd tmp\n\nonly run second command when first command is successful \n\n\n\n```\nmyvar=\"hello\"\necho $myvar\necho ${myvar:offset}\necho ${myvar:offset:length}\necho ${myvar:2:3}    # 3 characters starting from character 2\necho ${myvar/l/L}    # replace the first match of a pattern\necho ${myvar//l/L}   # replace all matches of a pattern\n```\n\n/l/L replace first l with L\n\n//l/L replace all l with L\n\n```bash\ntouch hello \"hello there\" \"hi there\" \"good morning, everyone\"\nls *\\ * # List all the file with space in the filename\nfor file in *\\ *\ndo \necho mv \"$file\" ${file// /_}  # we need to include the file name in \"\" because the name is long with space\ndone\n```\n\n\n\nQuestion 20 \n\n```\nWrite a loop that concatenates all .pdb files in data-shell/molecules subdirectory into one file called allmolecules.txt, prepending each fragment with the name of the corresponding .pdb file, and separating different files with an empty line. Run the loop, make sure it works, bring it up with the \"up arrow\" key and paste in here.\n```\n\n```bash\nfor file in *.pdb\ndo\necho ----- $file >> allmolecules.txt\ncat $file >> allmolecules.txt\necho >> allmolecules.txt\ndone\n```\n\n```\nTOPICCreate a loop that writes into 10 files chapter01.md, chapter02.md, ..., chapter10.md. Each file should contain chapter-specific lines, e.g. chapter05.md will contain exactly these lines:\n## Chapter 05\nThis is the beginning of Chapter 05.\nContent will go here.\nThis is the end of Chapter 05.\n```\n\n```bash\nfor i in {01..10} \ndo \necho \\#\\# Chapter i > chapter\"$i\".md\necho This is the beginning of Chapter \"$i\" >> chapter\"$i\".md\necho Content will go here. >> chapter\"$i\".md\necho This is the end of Chapter \"$i\". >> chapter\"$i\".md\ndone\n```\n\nIts safe to put the expressions in quotes.\n\n## Scripts and functions\n\n### Shell scripts\n\n.sh \n\n```bash\n#!/bin/bash\n```\n\nThe shebang tells where to find interpreters.\n\n\n\nRun:\n\n1) bash process.sh\n\n2) change it to executable \n\nattributes\n\nrwx rwx rwx : the first set refers to ==the owner of the file (i.e., the user)==; the second set refers to ==the group that owns the file==; the third set refers to ==everybody else on the system==.\n\n``` bash\nchmod u+x process.sh\n```\n\nAdd executable permission of the user to this file.\n\nthen we run\n\n```bash\n./process.sh\n```\n\n**Note: You are unable to run the file through `process.sh`, because this command is not the PATH**\n\n```bash\n# this is shebang, which tells the compiler where to find interpreters.\n#!/bin/bash\n\n#echo hello world!\n\n# return the first second and third argument passed to the script.\n#echo $1 $2 $3\n\n# return all arguments passed to it\n#echo the arguments are $@\n\n\nfor word in $@\ndo\necho $word\ndone\n\n```\n\nWhen you run the above code, give the input as \n\n```bash\n./process.sh A B C D FUCK\t\n```\n\n#### Example\n\n```bash\nfor molecule in $@\ndo\n  echo $molecule\n  head -3 $molecule\n  wc -l $molecule\n  echo -----\ndone\n\n```\n\nyou could run:\n\n```bash\n./process.sh *.pdb\n# or\n./process.sh ethane.pdb cubane.pdb\n```\n\n\n\n### Variables\n\n```bash\nmyvar=3\nexport myvar1=5\n\n```\n\nWhen using `export`, the variable could be inherited by the scripts (say creating a new bash file. The variable could be accessed inside this shell.). However, without this, the variable is only available outside the script.\n\n\n\n`printenv` or `env` will print all the environment variables. \n\n\n\nTo reset a variable, use  \n\n```bash\nunset myvar1\n```\n\n`$HOME` variable  -- home directory\n\n`$PATH` variable, where shell will look for interpreters.\n\n`$PWD` variable --- stores current directory\n\n`$PS1` variable ---- stores the format of the prompt\n\nFor example, if the $PS1 is \t`[\\u@\\h \\W]\\$` , the prompt looks like this <img src=\"D:\\Dropbox\\Dropbox\\Grad_Study\\Westgrid_Summer_School\\Fig\\image-20200527133916746.png\" alt=\"image-20200527133916746\" style=\"zoom: 50%;\" />\n\nUsing `which ls` could find out where 'ls' file locates.\n\n### Functions\n\nFunctions are similar to scripts, except that we reference a function by its name. Therefore, **once defined, a function can be run in any directory**, whereas running a script in another directory requires its path.\n\nA convenient place to put all your function definitions is `~/.bashrc` file which is run every time you start a new shell (local or remote).\n\n```bash\n# define a function \ngreeting(){\necho hello!\n}\n# see the function\ntype greeting\n\n# run the function\ngreeting\n\n```\n\n`$@` show the values of arguments \n\n`$#` show the number of arguments\n\nwe could write the function in a .sh file\n\n```bash\nfunction greeting(){\n\n\n}\nfunction combine(){\n\n}\n```\n\nafter that we need to ==`source function.sh`==to load the definition into the shell. Every time you change the definition of the function, you have to execute source again.\n\n\n\n#### A complicated example of Function\n\n`$RANDOM` will generate random integer.\n\n```bash\nfunction combine(){\n  if [ $# -eq 0]; then\n  \techo No arguments specified. Usage: combine file1 [file2 ...]\n  \treturn 1\n  fi \n  dir=$RANDOM$RANDOM\n  mkdir $dir\n  mv $@ $dir\n  echo moved these files into $dir successfully.\n  \n}\n```\n\n\n\n`.bashrc`: Could put the function definitions into this file. Then when the shell is started, the `.bashrc` will be loaded. So you dont need to source your function everytime\n\n## Grep and find\n\n### Searching inside files with `grep` \n\n```bash\n# partly matching\ngrep day haiku.txt\n\n#exactly matchig\ngrep -w day haiku.txt\n```\n\n- `grep` is case-sensitive \n- -i ---> set grep to case insensitive\n- -n   ---> return line number\n- -v  ---> print all the lines that DOESN'T match\n- more flags: see `man grep`\n- \n\n### Finding files with `find`\n\n```bash\n#search the file with name of 'haiku.txt' within current directory\nfind . -name haiku.txt\n\n# search the file with name of 'haiku.txt' within current directory and its child directories\nfind . -name \"*.txt\"\n\n\n# This works the same as the first command\n# This because The bash will expand the pattern of *.txt'; then do the find\nfind . -name *.txt \n\n#find all with the type of file\nfind . -type f\n\n#find all with the type of directory\nfind . -type d\n\n# setting searching depth.\nfind . -maxdepth 1 -type d\n \n```\n\n\n\n### Combing `find` and `grep`\n\n```bash\n# aggregate the result \n$(find . -name \"*.txt\")\n\nfor file in $(find . -name \"*.txt\")\ndo\n  grep day $file\ndone\n\n# Another way\n\nfind . -name \"*.txt\" | xargs grep day\n```\n\n==xargs==\n\nThe `xargs` command in UNIX is a command line utility for building an execution pipeline from standard input. Whilst tools like [`grep`](https://shapeshed.com/unix-grep/) can accept standard input as a parameter, many other tools cannot. Using `xargs` allows tools like `echo` and [`rm`](https://shapeshed.com/unix-rm/) and [`mkdir`](https://shapeshed.com/unix-mkdir/) to accept standard input as arguments.\n\nFor more, refer to https://shapeshed.com/unix-xargs/\n\n## Text Manipulation\n\n### Text manipulation\n\nGoals: learn `sed` `tr`   --- tr --- stands for translate /// translate or delete characters\n\n`sed`: stream editor for filtering and transforming text\n\n**GNU version of sed and BSD version of sed have different options and arguments.**\n\n*Using Address Ranges*: Addresses let you target specific parts of a text stream. You can specify line or even a range of lines.\n\n```bash\n# Using sed to convert all 'invisible' to 'supervisible'\n\nsed 's/[Ii]nvisible/supervisible/g' wellinvisibleMan.txt > supervisible.txt\n# 's' specifies the substitution operation ; By default, sed all only convert first match of each line; hence, we need to add 'g'\n\n\n```\n\nFor `sed` command\n\n`s/regexp/replacement` : Attempt to match *regexp* (could apply regular expression) against the pattern space. If successful, replace that portion matched with *replacement*. The *replacement* may contain the special character & to refer to that portion of the pattern space which matched, and the special escapes \\1 throughout \\9 to refer to the corresponding matching sub-expressions in the *regexp*\n\n\n\n==The character after the *s* is the delimiter. Pick one you like. As long as it's not in the string you are looking for, anything goes.== And remember that you need three delimiters. If you get a \"Unterminated `s' command\" it's because you are missing one of them.\n\nFor example: \n\n```bash\nsed 's/\\/usr\\/local\\/bin/\\/common\\/bin/' <old >new\n\nsed 's_/usr/local/bin_/common/bin_' <old >new\n```\n\n==`` is the same as \\$( ). The command will execute within brackets and then the results will be returned. It's better to use \\$( ).==\n\n```bash\n# Delete all punctuation marks\n\ncat well.txt | tr -d \"[:punct:]\" > a1.txt\n\n# Note There are some expressions specifically for tr command\n# For example: [:punct:] --- all punctuation characters\n# [:digit:]---- all digits\n# Refer to   man tr\n\n# uppercase to lowercase\n\ncat a1.txt | tr '[:upper:]' '[:lower:]' > a2.txt\n\n# replace space with \\n\n\ncat a2.txt | sed 's/ /\\'$'\\n/g' > a3.txt\n# I think we could just use \ncat a2.txt | sed 's/ /\\n/g' > a3.txt\n\n# \\'$'\\n  short for new line\n\n# remove empty lines\nsed '/^$/d' a3.txt > a4.txt\n\n#\ncat a4.txt | sort | uniq -c > a5.txt\n\n# return unique words and their counts\n\ncat a5.txt | sort -gr > a6.txt\n# -g --->compare according to general numerical value\n# -r ---> reverse the result of comparisons(from max to min)\n\n\n```\n\nMore refer to:\n\n1) https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux \n\n2) https://www.digitalocean.com/community/tutorials/using-grep-regular-expressions-to-search-for-text-patterns-in-linux\n\n3) https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/\n\n4) https://www.geeksforgeeks.org/sed-command-linux-set-2/\n\n### Column-based Text processing with `awk` scripting language\n\n```bash\nawk '{print $1}' haiku.txt\n\n# $1 --the first field, that is first word of each line in this case.\n# $0 --full line\n\nawk '{print}' haiku.txt  # also print all\n\n# Specify other separators between words (default is space)\n\nawk -Fa '{print $1}' haiku.txt   # set 'a' as the seperator\n\n\nawk 'NR>1' haiku.txt  # print the number of record greater than 1,i.e, all lines except the first line\n\nawk 'NR>2' haiku.txt\n\nawk 'NR>2 && NR<5' haiku.txt # print line 3 and 4\n```\n\n\n\n## Fuzzy finder\n\nFuzzy finder `fzf` is a third-party tool, not installed by default. With basic usage, it does interactive processing of standard input. At a more advanced level (not covered in the video below), it provides key bindings and fuzzy completion.\n\n\n\nFuzzy finder is an interactive finding tools. We could also pipe the return results into other commands.\n\n```bash\n#Example 1\n\nnano $(find ./molecules -type f | fzf --height 40%)\n# -- height 40% is used to set height of the fzf windows as 40% of the full screen\n# Once you choose the file, it will be opened in nano\n\n#Example 2\nkill -9 $(ps aux | fzf | awk '{print $2}')\n# ps -- list all the proecess, find the process you want to kill, awk will take only the ID, then kill will kill this process\n\n# Example 3\nemacs $(find ~/Documents/ -type f | fzf)\n\n```\n\n\n\n## Excerise -Day2\n\n\n\nls -l $(which gcc)\n\n\n\ngrep ATOM $(find . -name \"*.pdb\")\n\n\n\nQuestion 8 : Write a function `archive()` to replace directories with their gzipped archives.\n\n\n\n```bash\nfunction archive(){\nfor dir in $@\n\tdo\n\ttar cvf ${dir/\\/}.tar.gz $dir/ && /bin/rm -r $dir\n\t# The command after && will be executed only after the previous command is successfully executed\n\tdone\n}\n```\n\n\n\nQuestion 9\n\nWrite a one-line command that finds 5 largest files in the current directory and prints only their names and file sizes in the human-readable format (indicating bytes, kB, MB, GB, ...) in the decreasing file-size order. Hint: use **find**, **xargs**, and **awk**.\n\n\n\n```bash\nfind . -type f| xargs ls -lSh | awk '{print 5 \"   \" 9}' | head -5\n\n# For ls command, -h ---> humman-readable sizes (K, M, G...)   -S -->sort by file size, largest first \n```\n\n\n\n## Appendix 1 Regular Expressions\n\nRegular expressions could be used in almost every computer language.\n\n\n\n### Basic Regular expressions\n\n| Symbol | Descriptions                                          |\n| ------ | ----------------------------------------------------- |\n| ==^==  | matches start of string                               |\n| ==$==  | matches end of string                                 |\n| .      | replaces any character                                |\n| ==\\\\== | represent special characters                          |\n| ()     | groups regular expressions                            |\n| *      | matches up zero or more times the preceding character |\n\n\n\n```bash\ncat sample | grep ^a # search content that starts with 'a'\ncat sample | grep a$ # search content that ends with'a'\ngrep \"d.g\" file1 # Search for words that start with 'd', end with 'g', and have any character in the middel. If there are six dots, that means six characters in the middle.\ngrep \"N[oen]n\" file1 # 'o' or 'e' or 'n'; [a-e]  a range of chracters\n[^1-9] #==> all characters except number 1 to 9.\ngrep \"lak*\" file1 # match any number of occurrences of the preceding letter, including none\n\n```\n\n\n\n### Interval Regular Expressions\n\n| Expression | Descriptions                                                 |\n| ---------- | ------------------------------------------------------------ |\n| {n}        | Matches the preceding character appearing n times exactly    |\n| {n,m}      | Matches the preceding character appearing n times but no more than m times |\n| {n,}       | Matches the preceding character only when it appears n times or more |\n\n\n\n```bash\ncat sample | grep -E p\\{2} # -E --> extended regular expressions\n# find the content with 'p' appearing exactly 2 times in a string one after the oter.(two consecutive 'p')\n\n```\n\n\n\n### Extended Regular Expressions\n\n| Expression | Description                                              |\n| ---------- | -------------------------------------------------------- |\n| \\\\+        | Matches one or more occurrence of the previous character |\n| \\\\?        | Matches zero or one occurrence of the previous character |\n\n```bash\ncat sample | grep \"a\\+t\"\n# Or\ncat sample | grep -E a\\+t\n\ngrep \"ba\\?b\" file1\n```\n\n### Brace (大括号) expansion \n\nThe syntax for brace expansion is either a sequence or a comma separated list of items inside curly braces \"{}\".\n\n```bash\n{aa,bb,cc,dd}  # ==> aa bb cc dd\n{1..9}  # ==> 1 2 3 4 5 6 7 8 9\n```\n\n###Shorthand Characters\n\n| Character | Description                                      |\n| --------- | ------------------------------------------------ |\n| \\s        | match whitespaces (a space, a tab or line break) |\n| \\d        | match digits == [0-9]                            |\n| \\w        | match all the word characters (A-Z a-z) AND _    |\n| \\S        | opposite of \\s                                   |\n| \\D        | opposite of \\d                                   |\n| \\W        | opposite of \\w                                   |\n\n### Word Boundaries\n\n| Character | Description                                                  |\n| --------- | ------------------------------------------------------------ |\n| \\\\<       | used for beginning of the ==word==                           |\n| \\\\>       | used for end of the ==word==                                 |\n| \\\\b       | used for either beginning or end of the ==word==, could replace \\\\< or \\\\> |\n\n```bash\ngrep \"e\\>\" sample #locate words with 'e' at the end\ngrep \"\\<a\" sample # locate word with 'a' in the beggining\ngrep \"t\\b\" sample # locate word with 't' at the end\ngrep \"\\bt\\|t\\b\" sample # locate words with t in the beginning or at the end\n# Because grep use basic regular expression, we need to escaple | .Or use -E or -P\n```\n\n\n\n### Anchor\n\n|      |                                   |\n| ---- | --------------------------------- |\n| ^    | used to beginning of the ==line== |\n| $    | used for end of the ==line==      |\n\n\n\n### References\n\n1. https://www.guru99.com/linux-regular-expressions.html\n2. \n\n## Q&A\n\n### 1. Single quote, double quote, brackets and backstick\n\n- ==\\`...\\` is the same as \\$(...). The command will execute within brackets and then the results will be returned. It's better to use \\$( ).==\n\n- single quote will not interpolate anything, but double quotes will. (like variables, backticks, certain \\ escapes). When you enclose characters or variable with single quote then it represents the literal value of the character. Besides, a single quote can't be used within another single quote.\n\n  Example:\n\n  ```bash\n  num=3\n  echo '$num'\n  >> $num\n  echo \"$num\"\n  >> 3\n  ```\n\n  如果想让“ ” 里面输出$,需要加 \\\n\n  - If you use any space between the string values then they will be treated as separate value and print separately.\n\n    ```bash\n    printf '%s\\n' \"Ubuntu\"\"Centos\"\n    >> UbuntuCentos\n    printf '%s\\n' \"Ubuntu\" \"Centos\"\n    >> Ubuntu\n       Centos\n    ```\n\n  <u>References:</u>\n\n  [https://linuxhint.com/bash_escape_quotes/#:~:text=The%20dollar%20sign%20(%20%24%20)%20and,backticks%2C%20double%20quote%20and%20backslash.](https://linuxhint.com/bash_escape_quotes/#:~:text=The dollar sign ( %24 ) and,backticks%2C double quote and backslash.)\n\n  ","tags":["Shell"]},{"title":"greetings","url":"/2020/02/18/greetings/","content":"\n这是一个语言测试的页面。"},{"title":"SICL&SIW","url":"/2020/02/18/SICL-SIW/","content":"## SICL\n\nSubstrate Integrated Coaxial Line\n\n- Shielded structure, non-dispersive\n- easy to integrated\n\nMicrostrip lines:\n\n- Easy to fabricate \n- not shielded\n- loss due to radiation and cross-talk\n\nStrip Lines:\n\n- lateral leakage \n- cross-talk\n\n### Composition\n\n- A conductive thin film sandwiched between two  grounded dielectric layers and side-limited by two rows of metallic via holes (Fig.1)\n\n![](.\\pic\\SICL_Geometry.PNG)\n\n- Propagate TEM mode similar to strip line\n\n- Lateral shielding (侧面的) due to metallic holes avoids the propagation of the unwanted *parallel-plate mode* , which could be excited by any discontinuity, causing leakage and interferences with other lines. \n\n- First upper mode: TE10 mode, same as SIW, because central conductor does not affect its model field structure. **why?** \n\n- Suppose above is true. Cut-off freq of TE10 mode\n  $$\n  f_{TE10}=\\frac{c}{2\\sqrt{\\epsilon_r}}(A-\\frac{D^2}{0.95S})^{-1}\n  $$\n  A D S is shown in Fig.1. Usually, D and S is restricted by manufacturing technologies. Thus, A could be adjusted to control the TE10 freq. \n\n- Characteristic impedance Z0\n\n  For TEM wave, Z0 is freq. independent. **Thus Z0 could be controlled by the ratio between 2H and W.**\n\n### Example\n\nUnimodal operation at 4GHz\n\n\n\n### Reference\n\n[1] F. Gatti, M. Bozzi, L. Perregrini, K. Wu, and R. G. Bosisio, “A Novel Substrate Integrated Coaxial Line ( SICL ) for Wide-Band Applications,” in 36th European Microwave Conference, 2006, no. September, pp. 1614–1617.\n\n## SIW/SISW\n\nDispersive-- not suitable for wideband applications\n\n*Review of substrate-integrated waveguide circuits and antennas*, 2010, K.Wu\n\n- For higher frequency, like millimeter-wave, the microstrip lines and coplanar waveguides presents high transmission and radiation losses.\n\n- SIW has been applied in several microwave components\n- Application in frequency over 30 GHz cases is much less, because the technology needed to manufacture the miniaturized dimensions, losses and material selection restricts.\n\n### SIW structure\n\n## SIW circuits and antennas review\n\n### 2 Structure\n\n#### 2.1 Operation principles\n\nUsually $TE_{n0}$ modes are supported, but TM modes are not supported by SIW, due to the gaps between the metal vias: **in fact, transverse magnetic fields determine longtitudinal surface currents, which are subject to strong radiation due to the presence of the gaps.**\n\nThe following figure shows the field distribution of TM11, TM21 mode in rectangular waveguide. It could be seen that the the E field terminates at the transverse wall. Due to the gaps between metal vias, the field will leaked outside the SIW. \n\n![](.\\pic\\TM_RectWG.PNG)\n\nThe estimation for the effective width of SIW is\n$$\nw_{eff} = w-\\frac{d^2}{0.95s}\n$$\nwhere d is the diameter of the metal vias, w represents their transverse spacing and the s ithe longitudinal spacing ( shown in the following figure)\n\n![](.\\pic\\Geometry_SIW.PNG)\n\n(2) could be refined in many relations.\n\n#### 2.2 Loss mechanisms\n\nloss is critical when SIW works at millimeter wave freqs.\n\nThree loss sources:\n\n- conductor loss ---> finite condutivity of the metal walls\n- dieletric loss --> lossy dielectric material\n- possibly radiation loss  --> energy leakage through the gaps\n\nSolutions:\n\n- For condutor loss: increase substrate thickness (attenuation constant proportional to the inverse of substrate thickness)\n- Dielectric loss: use better material. dimesion changes won't help\n- Radiation loss: **radiation losses can be kept reasonably small if s/d<2.5, with s/d= 2 being the recommended value. **\n\nInsertion loss could be significantly increased by the effect of surface roughness in condutors.\n\n\n\nLoss comparison between SIW, Microstrip, CPW: generally comparable losses compared to traditional planar transmission lines.\n\n#### 2.4 Size and bandwidth\n\nwidth of SIW--> cutoff freq of fundamental mode\n\noperation bandwidth --> one octave ( from cutoff freq f1 of TE10 TO cutoff freq f2 of TE20 mode\n\n![](.\\pic\\new SIW_type.PNG)\n\n- SIFWL: reduce size by more than 2, slightly larger losses\n- HMSIW: \n- SISW: improve bandwidth, 7.5 - 18GHz (with 40% bandwidth enhancement)\n- Ridge SIW: the ridge was implemented through a row of thin, partial-height metal posts located in the centre of the longer side of the waveguide. 4.9 - 13.39 GHz, with 73% bandwidth enhancement. There is a lot has been done to further improve the bandwidth. ...\n\n### 3 SIW passive circuits\n\n#### 3.1 Filters and couplers\n\n**inductive post**:\n\nMetal post(柱) or screw（螺钉） extending across a waveguide parallel to the *E* field, to add *inductive susceptance* in parallel with the waveguide for tuning or matching purposes. \n\n![](.\\pic\\WG_Impedance_Matching.PNG)\n\nReference:  https://www.radartutorial.eu/03.linetheory/tl16.en.html \n\n**iris**:\n\ndiaphragm consisting of thin overlapping plates that can be adjusted to change the diameter of a central opening.\n\n#### 3.2 Transitions\n\n### 4 SIW active circuits\n\nOscillators, Mixers, Amplifiers\n\n### 5 SIW antennas\n\n- SIW slotted antenna [1]\n\n- leaky-wave antennas \n\n  - longitudinal spacing leakage [2]\n  - Based on TE20 mode[3]\n\n- Modified Vivaldi radiator [4]\n\n- Cavity-backed SIW antennas \n\n  - slotted SIW cavity fed by a CPW[5]\n\n  - slotted SIW cavity with meander line and fed by a MS line[6]\n\n  - Ku-band xxx, 2 by 2 array of metal patches[7]\n\n    ![](.\\pic\\Mohamed.A_2009_cavity_backed_2_by_2_array.PNG)\n\n    ![](.\\pic\\Mohamed.A_2009_cavity_backed_2_by_2_array_fabricated.PNG)\n\n- H-plane sectoral horn antenna, with dieletric loading, high gain and narrow beamwidths [8]\n\n\n\nReference:\n\n[1] Yan, L., Hong, W., Hua, G., Chen, J., Wu, K., Cui, T.J.: ‘Simulation and experiment on SIW slot array antennas’, IEEE Microw. Wirel. Compon. Lett., 2004, 14, (9), pp. 446–448.\n\n[2]Deslandes, D., Wu, K.: ‘Substrate integrated waveguide leaky-wave antenna: concept and design considerations’. Asia-Pacific Microwave Conf. Proc. (APMC’05), Suzhou, China, 2005\n\n[3] Xu, F., Wu, K., Zhang, X.: ‘Periodic leaky-wave antenna for millimeter wave applications based on substrate integrated waveguide’, IEEE Trans. Antennas Propag., 2010, 58, (2), pp. 340–347\n\n[4] Cheng, Y.J., Hong, W., Wu, K.: ‘Design ofa monopulse antenna using a dual V-type linearly tapered slot antenna (DVLTSA)’, IEEE Trans. Antennas Propag., 2008, 56, (9), pp. 2903–2909\n\n[5] Luo, G.Q., Hu, Z.F., Dong, L.X., Sun, L.L.: ‘Planar slot antenna backed by substrate integrated waveguide cavity’, IEEE Antennas Wirel. Propag. Lett., 2008, 7, pp. 236–239\n\n[6] Bohorquez, J.C., Pedraza, H.A.F., Pinzon, I.C.H., Castiblanco, J.A., Pena, N., Guarnizo, H.F.: ‘Planar substrate integrated waveguide cavity-backed antenna’, IEEE Antennas Wirel. Propag. Lett., 2009, 8, pp. 1139–1142\n\n[7] Awida, M.H., Fathy, A.E.: ‘Substrate-integrated waveguide Ku-band Wirel. Propag. Lett., 2009, 8, pp. 1054–1056 cavity-backed 2 × 2 microstrip patch array antenna’, IEEE Antennas\n\n[8] Wang, H., Fang, D.-G., Zhang, B., Che, W.-Q.: ‘Dielectric loaded substrate integrated waveguide (SIW) – plane horn antennas’, IEEE Trans. Antennas Propag., 2010, 58, (3), pp. 640–647\n\n### 6 SIW active antennas\n\n","tags":["Microwave"]}]